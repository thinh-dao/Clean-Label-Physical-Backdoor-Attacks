{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "\n",
    "from forest.victims.training import run_step\n",
    "from forest.utils import write, ReparamModule, set_lr\n",
    "from forest.consts import FINETUNING_LR_DROP, PIN_MEMORY, NORMALIZE, NON_BLOCKING\n",
    "from forest.witchcoven import _Witch\n",
    "from forest.data.datasets import Subset, ConcatDataset, LabelPoisonTransform\n",
    "from torch.utils.data import DataLoader\n",
    "from forest.data.datasets import normalization\n",
    "\n",
    "class WitchMTTP(_Witch):\n",
    "    def _distill_tesla_full_data(self, poison_delta, poison_bounds, poison_dataloader, student_net, starting_params, target_params, kettle, syn_steps=2, syn_lr=0.001, loss_fn=torch.nn.CrossEntropyLoss()):\n",
    "        # Initialize tracking variables\n",
    "        poison_delta.requires_grad_(True)  # Ensure poison_delta tracks gradients\n",
    "\n",
    "        # Initialize student parameters (tracked across steps)\n",
    "        student_params = [starting_params.detach().clone().requires_grad_(True)]  # Starting point\n",
    "        \n",
    "        x_list = []\n",
    "        y_list = [] \n",
    "        poison_slices_list = []\n",
    "        batch_positions_list = []\n",
    "        gradient_sum = torch.zeros_like(student_params[-1]).to(self.setup['device'])\n",
    "        \n",
    "        # Calculate parameter distance for normalization\n",
    "        param_dist = torch.norm(target_params - starting_params) ** 2\n",
    "\n",
    "        # Train student network with manual parameter updates\n",
    "        for step in range(syn_steps):\n",
    "            loss = 0\n",
    "            for inputs, labels, idx in poison_dataloader:\n",
    "                inputs = inputs.to(**self.setup)\n",
    "                labels = labels.to(dtype=torch.long, device=self.setup['device'], non_blocking=NON_BLOCKING)\n",
    "                \n",
    "                # Apply poison perturbations only to designated poison samples\n",
    "                poison_slices, batch_positions = kettle.lookup_poison_indices(idx)\n",
    "                \n",
    "                if len(batch_positions) > 0:\n",
    "                    delta_slice = poison_delta[poison_slices].to(**self.setup)\n",
    "                    if self.args.clean_grad:\n",
    "                        delta_slice = torch.zeros_like(delta_slice) + 0 * delta_slice  # Trick to preserve gradients\n",
    "                    poison_bounds[poison_slices] = inputs[batch_positions].clone().detach().cpu()\n",
    "                    inputs[batch_positions] = inputs[batch_positions] + delta_slice\n",
    "\n",
    "                    # Save poison slices and batch positions\n",
    "                    poison_slices_list.append(poison_slices)\n",
    "                    batch_positions_list.append(batch_positions)\n",
    "                    \n",
    "                    # Save original inputs (now with poison applied to specific samples)\n",
    "                    x_list.append(inputs.clone().cpu())\n",
    "                    y_list.append(labels.clone().cpu())\n",
    "                \n",
    "                # Data augmentation (applied to all images, poisoned and clean)\n",
    "                if self.args.paugment:\n",
    "                    inputs = kettle.augment(inputs)\n",
    "                if NORMALIZE:\n",
    "                    inputs = normalization(inputs)\n",
    "                \n",
    "                # Forward pass through student network\n",
    "                forward_params = student_params[-1].to(**self.setup)\n",
    "                outputs = student_net(inputs, flat_param=forward_params)\n",
    "                student_loss = loss_fn(outputs, labels)\n",
    "\n",
    "                loss += student_loss.item()\n",
    "                \n",
    "                # Compute gradients for parameters\n",
    "                grad = torch.autograd.grad(student_loss, forward_params)[0]\n",
    "                detached_grad = grad.detach().clone()\n",
    "                \n",
    "                # Only add to gradient_sum if the batch contains poisoned samples\n",
    "                if len(batch_positions) > 0:\n",
    "                    gradient_sum += detached_grad\n",
    "                \n",
    "                # Manual parameter update (always update parameters regardless of poisoning)\n",
    "                updated_params = forward_params - syn_lr * detached_grad\n",
    "                student_params.append(updated_params.cpu())\n",
    "                    \n",
    "                # Clean up GPU tensors\n",
    "                del grad, outputs, student_loss\n",
    "\n",
    "            loss /= len(poison_dataloader)\n",
    "            print(f\"Step {step+1} of {syn_steps} | Loss: {loss:.4f}\")\n",
    "            \n",
    "            # Create a tensor to hold poison gradients\n",
    "            poison_delta_gradients = torch.zeros_like(poison_delta)\n",
    "            gradient_sum = gradient_sum.to(self.setup['device'])\n",
    "            \n",
    "            # --------Compute the gradients regarding poison delta---------\n",
    "            # Compute gradients involving 2 gradients\n",
    "            for i in range(len(batch_positions_list)):\n",
    "                # Skip batches without poisoned samples\n",
    "                if len(batch_positions_list[i]) == 0:\n",
    "                    raise ValueError(f\"Batch {i} has no poisoned samples. There may be an error in the poison indices.\")\n",
    "                    \n",
    "                # Compute gradients for w_i\n",
    "                w_i = student_params[i].to(self.setup['device'])\n",
    "                x_i = x_list[i].to(self.setup['device'])\n",
    "                y_i = y_list[i].to(self.setup['device'])\n",
    "\n",
    "                inputs = x_i.clone()\n",
    "\n",
    "                if self.args.paugment:\n",
    "                    inputs = kettle.augment(inputs)\n",
    "                if NORMALIZE:\n",
    "                    inputs = normalization(inputs)\n",
    "\n",
    "                output_i = student_net(inputs, flat_param=w_i)\n",
    "                ce_loss_i = loss_fn(output_i, y_i)\n",
    "                grad_i = torch.autograd.grad(ce_loss_i, w_i, create_graph=True)[0]\n",
    "\n",
    "                single_term = syn_lr * (target_params - starting_params)\n",
    "                single_term = single_term.to(self.setup['device'])\n",
    "                square_term = (syn_lr ** 2) * gradient_sum\n",
    "                \n",
    "                # Compute gradients with respect to the original inputs (with poison applied)\n",
    "                total_term = 2 * (single_term + square_term) @ grad_i / param_dist.to(self.setup['device'])\n",
    "    \n",
    "                # Compute gradients only for poisoned samples\n",
    "                gradients = torch.autograd.grad(\n",
    "                    total_term,\n",
    "                    x_i,\n",
    "                )[0]\n",
    "                \n",
    "                if gradients is not None:\n",
    "                    poisoned_gradients = gradients[batch_positions_list[i]]\n",
    "                    poison_delta_gradients[poison_slices_list[i]] += poisoned_gradients.cpu()\n",
    "\n",
    "        # Calculate final loss with MSE between final parameters and target parameters\n",
    "        param_loss = torch.nn.functional.mse_loss(student_params[-1], target_params, reduction=\"mean\")\n",
    "        param_dist = torch.nn.functional.mse_loss(starting_params, target_params, reduction=\"mean\")\n",
    "        grand_loss = param_loss / param_dist.detach()\n",
    "        \n",
    "        # Assign gradients manually if needed\n",
    "        if torch.norm(poison_delta_gradients) > 0:\n",
    "            if poison_delta.grad is None:\n",
    "                poison_delta.grad = poison_delta_gradients\n",
    "            else:\n",
    "                poison_delta.grad += poison_delta_gradients\n",
    "        \n",
    "        for _ in student_params:\n",
    "            del _\n",
    "\n",
    "        return grand_loss\n",
    "\n",
    "    def _distill(self, poison_delta, poison_bounds, poison_dataloader, student_net, starting_params, target_params, kettle, syn_steps=2, syn_lr=0.001, loss_fn=torch.nn.CrossEntropyLoss()):\n",
    "        \"\"\"\n",
    "        Train a student network on poisoned data to match target network parameters.\n",
    "        Returns the distillation loss.\n",
    "        \"\"\"\n",
    "        poison_delta.requires_grad_(True)  # Ensure poison_delta tracks gradients\n",
    "\n",
    "        # Initialize student parameters (tracked across steps)\n",
    "        student_params = [starting_params.detach().clone().requires_grad_(True)]  # Starting point\n",
    "\n",
    "        # Train student network (manual parameter updates)\n",
    "        for step in range(syn_steps):\n",
    "            loss = 0\n",
    "            for inputs, labels, idx in poison_dataloader:\n",
    "                inputs = inputs.to(**self.setup)\n",
    "                labels = labels.to(dtype=torch.long, device=self.setup['device'], non_blocking=NON_BLOCKING)\n",
    "                \n",
    "                # Apply poison perturbations (with gradient tracking)\n",
    "                poison_slices, batch_positions = kettle.lookup_poison_indices(idx)\n",
    "                \n",
    "                if len(batch_positions) > 0:\n",
    "                    delta_slice = poison_delta[poison_slices].to(**self.setup)\n",
    "                    if self.args.clean_grad:\n",
    "                        delta_slice = torch.zeros_like(delta_slice) + 0 * delta_slice  # Trick to preserve gradients\n",
    "                    inputs[batch_positions] = inputs[batch_positions] + delta_slice\n",
    "                    poison_bounds[poison_slices] = inputs[batch_positions].detach().cpu()\n",
    "                \n",
    "                # Data augmentation\n",
    "                if self.args.paugment:\n",
    "                    inputs = kettle.augment(inputs)\n",
    "                if NORMALIZE:\n",
    "                    inputs = normalization(inputs)\n",
    "                \n",
    "                # Forward pass through student network\n",
    "                outputs = student_net(inputs, flat_param=student_params[-1].to(**self.setup))\n",
    "                student_loss = loss_fn(outputs, labels)\n",
    "\n",
    "                loss += student_loss.item()\n",
    "                \n",
    "                # Compute gradients for parameters\n",
    "                grad = torch.autograd.grad(student_loss, student_params[-1], create_graph=True, retain_graph=True)[0]\n",
    "                \n",
    "                # Manual parameter update\n",
    "                updated_params = student_params[-1] - syn_lr * grad\n",
    "                student_params.append(updated_params.cpu())\n",
    "            \n",
    "            loss /= len(poison_dataloader)\n",
    "            print(f\"Step {step+1} of {syn_steps} | Loss: {loss:.4f}\")\n",
    "\n",
    "        # Compute the distillation loss\n",
    "        param_loss = torch.nn.functional.mse_loss(student_params[-1], target_params, reduction=\"mean\")\n",
    "        param_dist = torch.nn.functional.mse_loss(starting_params, target_params, reduction=\"mean\")\n",
    "        grand_loss = param_loss / param_dist.detach()\n",
    "\n",
    "        # Backpropagate through the entire training process\n",
    "        grand_loss.backward()\n",
    "\n",
    "        # Update poison_delta (PGD-like optimizers)\n",
    "        if self.args.attackoptim in ['PGD', 'GD'] and len(batch_positions) > 0:\n",
    "            for i, (slice_idx, position) in enumerate(zip(poison_slices, batch_positions)):\n",
    "                delta_slice = poison_delta[slice_idx].to(**self.setup)\n",
    "                poison_image = inputs[batch_positions][i].detach()\n",
    "                updated_delta = self._pgd_step(delta_slice, poison_image, self.tau0, kettle.dm, kettle.ds)\n",
    "                poison_delta.data[slice_idx] = updated_delta.detach().cpu()\n",
    "\n",
    "        return grand_loss.item()\n",
    "\n",
    "    def _train_backdoor_net(self, backdoor_trainloader, backdoor_testloader, victim, kettle, lr, epochs, num_experts=1):\n",
    "        \"\"\"Train a backdoor network and collect multiple expert trajectories.\"\"\"\n",
    "        # Initialize list to store all expert trajectories\n",
    "        all_trajectories = []\n",
    "        \n",
    "        # Train multiple expert models if requested\n",
    "        for expert_idx in range(num_experts):\n",
    "            print(f\"Training expert {expert_idx+1}/{num_experts}\")\n",
    "            write(f\"Training expert {expert_idx+1}/{num_experts}\", self.args.output)\n",
    "            \n",
    "            # Create backdoor network\n",
    "            backdoor_net = copy.deepcopy(victim.model)\n",
    "            backdoor_optimizer = torch.optim.SGD(\n",
    "                backdoor_net.parameters(), \n",
    "                lr=lr, \n",
    "                momentum=0.9,\n",
    "                weight_decay=5e-4, \n",
    "                nesterov=True\n",
    "            )\n",
    "            \n",
    "            train_criterion = nn.CrossEntropyLoss()\n",
    "            \n",
    "            # Initialize trajectory for this expert\n",
    "            trajectory = []\n",
    "            \n",
    "            # Store initial model state\n",
    "            if hasattr(backdoor_net, 'module'):\n",
    "                initial_params = torch.cat([p.data.cpu().reshape(-1) for p in backdoor_net.module.parameters()], 0)\n",
    "            else:\n",
    "                initial_params = torch.cat([p.data.cpu().reshape(-1) for p in backdoor_net.parameters()], 0)\n",
    "            \n",
    "            trajectory.append(initial_params)\n",
    "            \n",
    "            # Train backdoor model\n",
    "            backdoor_net.train()\n",
    "\n",
    "            evaluate_every = max(1, epochs // 3)\n",
    "            for epoch in range(1, epochs+1):\n",
    "                avg_loss, accuracy = self._train_one_epoch(\n",
    "                    model=backdoor_net, \n",
    "                    trainloader=backdoor_trainloader, \n",
    "                    criterion=train_criterion, \n",
    "                    optimizer=backdoor_optimizer, \n",
    "                    diff_augment=kettle.augment,\n",
    "                    scheduler=torch.optim.lr_scheduler.CosineAnnealingLR(backdoor_optimizer, T_max=epochs)\n",
    "                )\n",
    "\n",
    "                write(f'Expert {expert_idx+1}, Epoch {epoch}/{epochs}: Train Loss: {avg_loss:.4f}, Train Accuracy: {accuracy:.4f}', self.args.output)\n",
    "                print(f'Expert {expert_idx+1}, Epoch {epoch}/{epochs}: Train Loss: {avg_loss:.4f}, Train Accuracy: {accuracy:.4f}')\n",
    "\n",
    "                # Collect model parameters after each epoch\n",
    "                if hasattr(backdoor_net, 'module'):\n",
    "                    epoch_params = torch.cat([p.data.cpu().reshape(-1) for p in backdoor_net.module.parameters()], 0)\n",
    "                else:\n",
    "                    epoch_params = torch.cat([p.data.cpu().reshape(-1) for p in backdoor_net.parameters()], 0)\n",
    "                \n",
    "                trajectory.append(epoch_params)\n",
    "\n",
    "                if epoch % evaluate_every == 0 or epoch == epochs:\n",
    "                    clean_acc, poisoned_acc, clean_loss, poisoned_loss = self._validation(\n",
    "                        backdoor_net, kettle.validloader, backdoor_testloader\n",
    "                    )\n",
    "                    write(f'Expert {expert_idx+1}, Epoch {epoch}/{epochs}: Clean Accuracy: {clean_acc:.4f}, Clean Loss: {clean_loss:.4f}, Poisoned Accuracy: {poisoned_acc:.4f}, Poisoned Loss: {poisoned_loss:.4f}', self.args.output)\n",
    "                    print(f'Expert {expert_idx+1}, Epoch {epoch}/{epochs}: Clean Accuracy: {clean_acc:.4f}, Clean Loss: {clean_loss:.4f}, Poisoned Accuracy: {poisoned_acc:.4f}, Poisoned Loss: {poisoned_loss:.4f}')\n",
    "            \n",
    "            # Add completed trajectory to the collection\n",
    "            all_trajectories.append(trajectory)\n",
    "\n",
    "        return all_trajectories\n",
    "    \n",
    "    def _run_trial(self, victim, kettle):\n",
    "        \"\"\"Run a single trial. Perform one round of poisoning.\"\"\"\n",
    "        # Initialize poison mask of shape [num_poisons, channels, height, width] with values in [-eps, eps]\n",
    "        poison_delta = kettle.initialize_poison()\n",
    "        poison_delta.requires_grad_(True)\n",
    "        # poison_delta.grad = torch.zeros_like(poison_delta).to(**self.setup) \n",
    "        dm, ds = kettle.dm.to(device=torch.device('cpu')), kettle.ds.to(device=torch.device('cpu'))\n",
    "        poison_bounds = torch.zeros_like(poison_delta)\n",
    "        \n",
    "        if self.args.full_data:\n",
    "            dataloader = kettle.trainloader\n",
    "        else:\n",
    "            dataloader = kettle.poisonloader\n",
    "\n",
    "        # Setup attack optimizer\n",
    "        if self.args.attackoptim in ['Adam', 'signAdam', 'momSGD', 'momPGD']:\n",
    "            poison_delta.requires_grad_()\n",
    "            if self.args.attackoptim in ['Adam', 'signAdam']:\n",
    "                att_optimizer = torch.optim.Adam([poison_delta], lr=self.tau0, weight_decay=0)\n",
    "            else:\n",
    "                att_optimizer = torch.optim.SGD([poison_delta], lr=self.tau0, momentum=0.9, weight_decay=0, nesterov=True)\n",
    "            \n",
    "            # Setup learning rate scheduler\n",
    "            if self.args.scheduling:\n",
    "                if self.args.poison_scheduler == 'linear':\n",
    "                    scheduler = torch.optim.lr_scheduler.MultiStepLR(\n",
    "                        att_optimizer, \n",
    "                        milestones=[self.args.attackiter // 2.667, self.args.attackiter // 1.6, self.args.attackiter // 1.142], \n",
    "                        gamma=0.1\n",
    "                    )\n",
    "                elif self.args.poison_scheduler == 'cosine':\n",
    "                    # Fixed comparison with None using 'is' instead of '=='\n",
    "                    if self.args.retrain_scenario is None:\n",
    "                        T_restart = self.args.attackiter+1\n",
    "                    else:\n",
    "                        T_restart = self.args.retrain_iter+1\n",
    "                    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "                        att_optimizer, T_0=T_restart, eta_min=0.0001\n",
    "                    )\n",
    "                else:\n",
    "                    raise ValueError(f'Unknown poison scheduler: {self.args.poison_scheduler}')\n",
    "        else:\n",
    "            raise ValueError(f'Unknown attack optimizer: {self.args.attackoptim}')\n",
    "        \n",
    "        # Initialize expert training trajectories (backdoor models)\n",
    "        backdoor_trainloader, backdoor_testloader = self._get_backdoor_data(kettle)\n",
    "        all_trajectories = self._train_backdoor_net(\n",
    "            backdoor_trainloader, \n",
    "            backdoor_testloader, \n",
    "            victim, \n",
    "            kettle, \n",
    "            lr=self.args.finetuning_lr, \n",
    "            epochs=self.args.backdoor_training_epoch, \n",
    "        )\n",
    "\n",
    "        for step in range(self.args.attackiter):\n",
    "            sample_traj_idx = np.random.randint(0, len(all_trajectories))\n",
    "            if self.args.sequential_generation:\n",
    "                expansion_end_epoch = self.args.attackiter // 5\n",
    "                if len(all_trajectories[sample_traj_idx]) - 1 < self.args.expert_epochs:\n",
    "                    max_start_epoch = 0\n",
    "                else:\n",
    "                    max_start_epoch = int ( (len(all_trajectories[sample_traj_idx]) - 1 - self.args.expert_epochs) * (step / expansion_end_epoch) )\n",
    "                start_params_idx = np.random.randint(0, max_start_epoch+1)\n",
    "            else:\n",
    "                max_start_epoch = max(len(all_trajectories[sample_traj_idx]) - 1 - self.args.expert_epochs, 0)\n",
    "                start_params_idx = np.random.randint(0, max_start_epoch+1)\n",
    "\n",
    "            starting_params = all_trajectories[sample_traj_idx][start_params_idx]\n",
    "\n",
    "            target_params_idx = min(start_params_idx + self.args.expert_epochs, len(all_trajectories[sample_traj_idx]) - 1)\n",
    "            target_params = all_trajectories[sample_traj_idx][target_params_idx]\n",
    "\n",
    "            # Create student network\n",
    "            student_net = copy.deepcopy(victim.model)\n",
    "\n",
    "            if hasattr(student_net, 'module'):\n",
    "                student_net = ReparamModule(student_net.module)\n",
    "            else:\n",
    "                student_net = ReparamModule(student_net)\n",
    "\n",
    "            # Distill from backdoor model to student model\n",
    "            distill_loss = self._distill_tesla_full_data(\n",
    "                poison_delta=poison_delta, \n",
    "                poison_bounds=poison_bounds, \n",
    "                poison_dataloader=dataloader, \n",
    "                student_net=student_net, \n",
    "                starting_params=starting_params, \n",
    "                target_params=target_params, \n",
    "                kettle=kettle\n",
    "            )\n",
    "\n",
    "            # Update poison perturbations\n",
    "            if self.args.attackoptim in ['Adam', 'signAdam', 'momSGD', 'momPGD']:\n",
    "                if self.args.attackoptim in ['momPGD', 'signAdam']:\n",
    "                    poison_delta.grad.sign_()\n",
    "                \n",
    "                att_optimizer.step()\n",
    "                \n",
    "                if self.args.scheduling:\n",
    "                    scheduler.step()\n",
    "\n",
    "                att_optimizer.zero_grad(set_to_none=False)\n",
    "                \n",
    "                # Project perturbations to valid range\n",
    "                with torch.no_grad():\n",
    "                    if self.args.visreg != None and \"soft\" in self.args.visreg:\n",
    "                        # Projection Step for soft regularization\n",
    "                        poison_delta.data = torch.clamp(poison_delta.data, min=0.0, max=1.0)\n",
    "                        # Then clamp to valid image range\n",
    "                        poison_delta.data = torch.clamp(\n",
    "                            poison_delta.data, \n",
    "                            min=-dm / ds - poison_bounds, \n",
    "                            max=(1 - dm) / ds - poison_bounds\n",
    "                        )\n",
    "                    else:\n",
    "                        # Projection Step for eps-bounded perturbations\n",
    "                        poison_delta.data = torch.clamp(\n",
    "                            poison_delta.data, \n",
    "                            min=-self.args.eps / ds / 255, \n",
    "                            max=self.args.eps / ds / 255\n",
    "                        )\n",
    "                        # Then clamp to valid image range\n",
    "                        poison_delta.data = torch.clamp(\n",
    "                            poison_delta.data, \n",
    "                            min=-dm / ds - poison_bounds, \n",
    "                            max=(1 - dm) / ds - poison_bounds\n",
    "                        )\n",
    "\n",
    "            # Calculate visual loss (L2 norm of perturbations)\n",
    "            with torch.no_grad():\n",
    "                visual_losses = torch.mean(torch.linalg.matrix_norm(poison_delta))\n",
    "            \n",
    "            # Log progress\n",
    "            if step % 1 == 0 or step == (self.args.attackiter - 1):\n",
    "                lr = att_optimizer.param_groups[0]['lr']\n",
    "                print(f'Iteration {step} - lr: {lr} | Distillation loss: {distill_loss:2.4f} | Visual loss: {visual_losses:2.4f}')\n",
    "                write(f'Iteration {step} - lr: {lr} | Distillation loss: {distill_loss:2.4f} | Visual loss: {visual_losses:2.4f}', self.args.output)\n",
    "                \n",
    "            # Step victim model if needed\n",
    "            if self.args.step and step % self.args.step_every == 0:\n",
    "                single_setup = (victim.model, victim.defs, victim.optimizer, victim.scheduler)\n",
    "                if self.args.clean_grad:\n",
    "                    run_step(kettle, None, step, *single_setup)\n",
    "                else:\n",
    "                    run_step(kettle, poison_delta, step, *single_setup)\n",
    "\n",
    "            if self.args.dryrun:\n",
    "                break\n",
    "            \n",
    "            if step > 0 and step % 10 == 0 or step == (self.args.attackiter - 1):\n",
    "                victim.validate(kettle, poison_delta, val_max_epoch=7)\n",
    "                all_trajectories = self._train_backdoor_net(\n",
    "                    backdoor_trainloader, \n",
    "                    backdoor_testloader, \n",
    "                    victim, \n",
    "                    kettle, \n",
    "                    lr=self.args.finetuning_lr, \n",
    "                    epochs=self.args.backdoor_training_epoch, \n",
    "                )\n",
    "\n",
    "            # Handle retraining scenario\n",
    "            if self.args.retrain_scenario is not None:\n",
    "                if step % self.args.retrain_iter == 0 and step != 0 and step != self.args.attackiter - 1:\n",
    "                    print(f\"Retraining the base model at iteration {step}\")\n",
    "                    poison_delta.detach()\n",
    "                    \n",
    "                    if self.args.retrain_scenario == 'from-scratch':\n",
    "                        victim.initialize()\n",
    "                        print('Model reinitialized to random seed.')\n",
    "                    elif self.args.retrain_scenario == 'finetuning':\n",
    "                        if self.args.load_feature_repr:\n",
    "                            victim.load_feature_representation()\n",
    "                        victim.reinitialize_last_layer(reduce_lr_factor=FINETUNING_LR_DROP, keep_last_layer=True)\n",
    "                        print('Completely warmstart finetuning!')\n",
    "\n",
    "                    victim._iterate(kettle, poison_delta=poison_delta, max_epoch=self.args.retrain_max_epoch)\n",
    "                    write('Retraining done!\\n', self.args.output)\n",
    "                    print('Retraining completed at step:', step)\n",
    "\n",
    "        return poison_delta, distill_loss\n",
    "\n",
    "    def _get_backdoor_data(self, data, backdoor_training_mode='all-data'):\n",
    "        \"\"\"Create backdoor training data by applying label transforms.\"\"\"\n",
    "        target_class = data.poison_setup['target_class']\n",
    "        \n",
    "        # Safely handle source_class whether it's a list or a single value\n",
    "        source_class = data.poison_setup['source_class']\n",
    "        if isinstance(source_class, list) and len(source_class) > 0:\n",
    "            source_class = source_class[0]\n",
    "        \n",
    "        # Verify classes exist in dataset\n",
    "        if not hasattr(data.triggerset_dist, 'keys') or source_class not in data.triggerset_dist:\n",
    "            raise ValueError(f\"Source class {source_class} not found in trigger dataset\")\n",
    "\n",
    "        # Create poisoned dataset with label transform\n",
    "        label_poison_transform = LabelPoisonTransform(mapping={source_class: target_class})\n",
    "        poisoned_triggerset = Subset(\n",
    "            data.triggerset, \n",
    "            data.triggerset_dist[source_class], \n",
    "            transform=data.trainset.transform, \n",
    "            target_transform=label_poison_transform\n",
    "        )\n",
    "\n",
    "        # Initialize backdoor trainset\n",
    "        if backdoor_training_mode == 'all-data':\n",
    "            backdoor_trainset = ConcatDataset([data.trainset, poisoned_triggerset])\n",
    "        else:\n",
    "            backdoor_trainset = poisoned_triggerset\n",
    "        \n",
    "        # Create data loaders\n",
    "        backdoor_trainloader = DataLoader(\n",
    "            backdoor_trainset, \n",
    "            batch_size=self.args.batch_size, \n",
    "            shuffle=True,\n",
    "            drop_last=False, \n",
    "            num_workers=4, \n",
    "            pin_memory=PIN_MEMORY\n",
    "        )\n",
    "        \n",
    "        backdoor_testloader = DataLoader(\n",
    "            poisoned_triggerset, \n",
    "            batch_size=self.args.batch_size*2, \n",
    "            shuffle=False,\n",
    "            drop_last=False, \n",
    "            num_workers=4, \n",
    "            pin_memory=PIN_MEMORY\n",
    "        )\n",
    "\n",
    "        return backdoor_trainloader, backdoor_testloader\n",
    "\n",
    "    def _validation(self, model, clean_testloader, poisoned_testloader):\n",
    "        \"\"\"Evaluate model performance on clean and poisoned data.\"\"\"\n",
    "        model.eval()\n",
    "        criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "        clean_corr = 0\n",
    "        clean_loss = 0\n",
    "        poisoned_corr = 0\n",
    "        poisoned_loss = 0\n",
    "        \n",
    "        # Get device from model or use the setup device\n",
    "        device = getattr(model, 'device', self.setup['device'])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Evaluate on clean data\n",
    "            for inputs, targets, idx in clean_testloader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                clean_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                clean_corr += predicted.eq(targets).sum().item()\n",
    "\n",
    "            # Evaluate on poisoned data\n",
    "            for inputs, targets, idx in poisoned_testloader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                poisoned_loss += loss.item()\n",
    "                _, predicted = outputs.max(1)\n",
    "                poisoned_corr += predicted.eq(targets).sum().item()\n",
    "\n",
    "        # Calculate metrics\n",
    "        clean_acc = clean_corr / len(clean_testloader.dataset)\n",
    "        poisoned_acc = poisoned_corr / len(poisoned_testloader.dataset)\n",
    "        clean_loss = clean_loss / len(clean_testloader.dataset)\n",
    "        poisoned_loss = poisoned_loss / len(poisoned_testloader.dataset)\n",
    "\n",
    "        return clean_acc, poisoned_acc, clean_loss, poisoned_loss\n",
    "\n",
    "    def _train_one_epoch(self, model, trainloader, criterion, optimizer, diff_augment=None, scheduler=None):\n",
    "        \"\"\"Train model for one epoch.\"\"\"\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        # Get device from model or use the setup device\n",
    "        device = getattr(model, 'device', self.setup['device'])\n",
    "        \n",
    "        for inputs, targets, idx in trainloader:            \n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            if diff_augment is not None:\n",
    "                inputs = diff_augment(inputs)\n",
    "                \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            if scheduler is not None:\n",
    "                scheduler.step()\n",
    "                \n",
    "            total_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        avg_loss = total_loss / len(trainloader)\n",
    "        accuracy = correct / total\n",
    "        return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output is logged in outputs/mttp/gradient-matching/tennis/RESNET18_IMAGENET/11-21_tennis_0.1_16_signAdam_250.txt\n",
      "Friday, 04. April 2025 01:24AM\n",
      "------------------ Currently evaluating gradient-matching ------------------\n",
      "Namespace(f='/home/thinh.dd/.local/share/jupyter/runtime/kernel-v37530071168a3d8c2b11b05acb48a6e805b485328.json', net=['resnet18_imagenet'], dataset='Animal_classification', recipe='gradient-matching', threatmodel='clean-single-source', num_source_classes=1, scenario='finetuning', poisonkey='11-21', system_seed=None, poison_seed=123456, model_seed=123456, deterministic=False, name='', poison_path='poisons/', model_savepath='models/', mixing_method=None, mixing_disable_correction=True, mixing_strength=None, disable_adaptive_attack=True, defend_features_only=False, gradient_noise=None, gradient_clip=None, defense_type=None, defense_strength=None, defense_steps=None, defense_sources=None, padversarial=None, pmix=False, attackoptim='signAdam', attackiter=250, init='randn', tau=0.1, scheduling=True, poison_scheduler='cosine', source_criterion='cross-entropy', restarts=1, finetuning_lr=0.001, backdoor_training_epoch=1, expert_epochs=1, sequential_generation=False, pbatch=64, paugment=True, data_aug='default', full_data=False, ensemble=1, stagger=None, step=False, train_max_epoch=40, ablation=1.0, loss='similarity', repel_loss=False, centreg=0, normreg=0, repel=0, visreg=None, vis_weight=1, htbd_full_params=False, featreg=0.0, scale=1.0, nadapt=1, clean_grad=False, vruns=1, vnet=None, retrain_from_init=False, skip_clean_training=False, optimization='conservative-sgd', batch_size=64, lr=0.1, noaugment=False, cache_dataset=False, dryrun=False, save_poison=None, save_clean_model=False, save_backdoored_model=False, exp_name='mttp', local_rank=None, keep_sources=True, sources_train_rate=0.75, sources_selection_rate=1.0, source_gradient_batch=64, val_max_epoch=40, retrain_max_epoch=20, retrain_scenario=None, load_feature_repr=True, train_from_scratch=False, trigger='tennis', digital_train=False, digital_test=False, digital_trigger_path='digital_triggers', opacity=0.12549019607843137, retrain_iter=100, source_selection_strategy=None, poison_selection_strategy='random', eps=16, alpha=0.1, defense=None, firewall=None, inspection_path=None, clean_budget=0.2, devices='4,3,2', random_placement=False, output='outputs/mttp/gradient-matching/tennis/RESNET18_IMAGENET/11-21_tennis_0.1_16_signAdam_250.txt')\n",
      "CPUs: 32, GPUs: 3 on vishc-server-1.\n",
      "GPU : NVIDIA GeForce RTX 3090\n",
      "resnet18_imagenet model initialized with random key 123456.\n",
      "Hyperparameters(name='conservative', epochs=40, batch_size=64, optimizer='SGD', lr=0.001, scheduler='linear', weight_decay=0.0005, augmentations='default', privacy={'clip': None, 'noise': None, 'distribution': None}, validate=10, novel_defense=None, mixing_method=None, adaptive_attack=True, defend_features_only=False)\n",
      "Normalization disabled.\n",
      "Initializing poison data with random seed 123456\n",
      "Setup triggerset\n",
      "Get class distribution of trainset\n",
      "Starting clean training with finetuning scenario ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 57\u001b[0m\n\u001b[1;32m     53\u001b[0m data \u001b[38;5;241m=\u001b[39m forest\u001b[38;5;241m.\u001b[39mKettle(args, model\u001b[38;5;241m.\u001b[39mdefs\u001b[38;5;241m.\u001b[39mbatch_size, model\u001b[38;5;241m.\u001b[39mdefs\u001b[38;5;241m.\u001b[39maugmentations,\n\u001b[1;32m     54\u001b[0m                     model\u001b[38;5;241m.\u001b[39mdefs\u001b[38;5;241m.\u001b[39mmixing_method, setup\u001b[38;5;241m=\u001b[39msetup) \u001b[38;5;66;03m# Set up trainloader, validloader, poisonloader, poison_ids, trainset/poisonset/source_testset\u001b[39;00m\n\u001b[1;32m     55\u001b[0m witch \u001b[38;5;241m=\u001b[39m WitchMTTP(args, setup\u001b[38;5;241m=\u001b[39msetup)\n\u001b[0;32m---> 57\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_max_epoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# Select poisons based on maximum gradient norm\u001b[39;00m\n\u001b[1;32m     60\u001b[0m data\u001b[38;5;241m.\u001b[39mselect_poisons(model)\n",
      "File \u001b[0;32m~/Clean-Label-Physical-Backdoor-Attacks/forest/victims/victim_base.py:122\u001b[0m, in \u001b[0;36m_VictimBase.train\u001b[0;34m(self, kettle, max_epoch)\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_model(model, save_path)\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_trained_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkettle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mload_feature_repr:\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_feature_representation()\n",
      "File \u001b[0;32m~/Clean-Label-Physical-Backdoor-Attacks/forest/victims/victim_single.py:313\u001b[0m, in \u001b[0;36m_VictimSingle.load_trained_model\u001b[0;34m(self, kettle)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    312\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(load_path))\n\u001b[0;32m--> 313\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_one_step_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkettle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m     write(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mnet[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found, training from scratch.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39moutput)\n",
      "File \u001b[0;32m~/Clean-Label-Physical-Backdoor-Attacks/forest/victims/victim_base.py:226\u001b[0m, in \u001b[0;36m_VictimBase._one_step_validation\u001b[0;34m(self, model, kettle)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_one_step_validation\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, kettle):\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;66;03m# Do evaluation on the loaded model\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m \u001b[43mrun_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkettle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mkettle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoison_setup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget_class\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mkettle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoison_setup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msource_class\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43mkettle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m kettle\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mthreatmodel \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall-to-all\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    232\u001b[0m         source_adv_acc, source_adv_loss, source_clean_acc, source_clean_loss \u001b[38;5;241m=\u001b[39m check_sources(\n\u001b[1;32m    233\u001b[0m             model, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn, kettle\u001b[38;5;241m.\u001b[39msource_testloader, kettle\u001b[38;5;241m.\u001b[39mpoison_setup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoison_class\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    234\u001b[0m             kettle\u001b[38;5;241m.\u001b[39msetup)\n",
      "File \u001b[0;32m~/Clean-Label-Physical-Backdoor-Attacks/forest/victims/training.py:256\u001b[0m, in \u001b[0;36mrun_validation\u001b[0;34m(model, criterion, dataloader, target_class, source_class, setup)\u001b[0m\n\u001b[1;32m    254\u001b[0m inputs \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msetup)\n\u001b[1;32m    255\u001b[0m labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39msetup[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, non_blocking\u001b[38;5;241m=\u001b[39mNON_BLOCKING)\n\u001b[0;32m--> 256\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    258\u001b[0m loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/flower-ba/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/flower-ba/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/flower-ba/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:193\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodule_kwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    192\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[: \u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 193\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/flower-ba/lib/python3.11/site-packages/torch/nn/parallel/data_parallel.py:212\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;28mself\u001b[39m, replicas: Sequence[T], inputs: Sequence[Any], kwargs: Any\n\u001b[1;32m    211\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Any]:\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/flower-ba/lib/python3.11/site-packages/torch/nn/parallel/parallel_apply.py:118\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m    116\u001b[0m         thread\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m thread \u001b[38;5;129;01min\u001b[39;00m threads:\n\u001b[0;32m--> 118\u001b[0m         \u001b[43mthread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m     _worker(\u001b[38;5;241m0\u001b[39m, modules[\u001b[38;5;241m0\u001b[39m], inputs[\u001b[38;5;241m0\u001b[39m], kwargs_tup[\u001b[38;5;241m0\u001b[39m], devices[\u001b[38;5;241m0\u001b[39m], streams[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/flower-ba/lib/python3.11/threading.py:1119\u001b[0m, in \u001b[0;36mThread.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1116\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot join current thread\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1119\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1121\u001b[0m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[1;32m   1123\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait_for_tstate_lock(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[38;5;241m0\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/flower-ba/lib/python3.11/threading.py:1139\u001b[0m, in \u001b[0;36mThread._wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m   1138\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1139\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1140\u001b[0m         lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m   1141\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"General interface script to launch poisoning jobs.\"\"\"\n",
    "\n",
    "import torch\n",
    "import os\n",
    "import forest\n",
    "\n",
    "from forest.utils import write, set_random_seed\n",
    "from forest.consts import BENCHMARK, SHARING_STRATEGY\n",
    "\n",
    "torch.backends.cudnn.benchmark = BENCHMARK\n",
    "torch.multiprocessing.set_sharing_strategy(SHARING_STRATEGY)\n",
    "\n",
    "# Parse input arguments\n",
    "args = forest.options().parse_args()\n",
    "args.exp_name = \"mttp\"\n",
    "args.devices = \"4,3,2\"\n",
    "args.attackiter = 250\n",
    "args.vruns = 1\n",
    "args.dataset = \"Animal_classification\"\n",
    "args.poisonkey = \"11-21\"\n",
    "args.trigger = \"tennis\"\n",
    "args.net = [\"resnet18_imagenet\"]\n",
    "args.eps = 16\n",
    "args.alpha = 0.1\n",
    "args.model_seed = 123456\n",
    "args.poison_seed = 123456\n",
    "args.tau = 0.1\n",
    "args.step = False\n",
    "args.scheduling = True\n",
    "args.full_data = False\n",
    "args.backdoor_training_epoch = 1\n",
    "args.expert_epochs = 1\n",
    "args.finetuning_lr = 0.001\n",
    "args.batch_size = 64\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=args.devices\n",
    "\n",
    "if args.system_seed != None:\n",
    "    set_random_seed(args.system_seed)\n",
    "\n",
    "# Set up output file\n",
    "args.output = f'outputs/{args.exp_name}/{args.recipe}/{args.trigger}/{args.net[0].upper()}/{args.poisonkey}_{args.trigger}_{args.alpha}_{args.eps}_{args.attackoptim}_{args.attackiter}.txt'\n",
    "print(\"Output is logged in\", args.output)\n",
    "os.makedirs(os.path.dirname(args.output), exist_ok=True)\n",
    "open(args.output, 'w').close() # Clear the output files\n",
    "\n",
    "####################################\n",
    "setup = forest.utils.system_startup(args) # Set up device and torch data type\n",
    "\n",
    "num_classes = len(os.listdir(os.path.join(\"datasets\", args.dataset, 'train')))\n",
    "model = forest.Victim(args, num_classes=num_classes, setup=setup) # Initialize model and loss_fn\n",
    "data = forest.Kettle(args, model.defs.batch_size, model.defs.augmentations,\n",
    "                    model.defs.mixing_method, setup=setup) # Set up trainloader, validloader, poisonloader, poison_ids, trainset/poisonset/source_testset\n",
    "witch = WitchMTTP(args, setup=setup)\n",
    "\n",
    "model.train(data, max_epoch=args.train_max_epoch)\n",
    "    \n",
    "# Select poisons based on maximum gradient norm\n",
    "data.select_poisons(model)\n",
    "# Print data status\n",
    "data.print_status()\n",
    "    \n",
    "if args.recipe != 'naive':\n",
    "    poison_delta = witch.brew(model, data)\n",
    "else:\n",
    "    poison_delta = None\n",
    "\n",
    "if args.retrain_from_init:\n",
    "    model.retrain(data, poison_delta) # Evaluate poison performance on the retrained model\n",
    "\n",
    "# Validation\n",
    "model.validate(data, poison_delta, val_max_epoch=args.val_max_epoch)\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flower-ba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
